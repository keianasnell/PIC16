{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We discussed in class that OpenCV comes with some handy functions, but that many of these you could write yourself with a few lines of Numpy. In this exam option, you'll show me that you can use these functions and also that you could write them yourself.\n",
    "\n",
    "<b>You should not use any loops in this exam option.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I suggest you start by storing absolute paths the the provided <tt>Bunny.jpg</tt> and <tt>donut.jpg</tt> in variables. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file2 = \"C:\\Users\\Matt\\Dropbox (Personal)\\UCLA\\Teaching\\PIC 16\\Exam\\Images\\Bunny.jpg\"\n",
    "file3 = \"C:\\Users\\Matt\\Dropbox (Personal)\\UCLA\\Teaching\\PIC 16\\Exam\\Images\\donut.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Write a function <tt>show(img)</tt> that, given an M x N x 3 (or M x N) Numpy array <tt>img</tt>, interprets the array as a BGR (grayscale) image and displays it in a separate window. The window should close and the function should terminate (cleanly) when the user presses any key or clicks the X button at the top right of the window.<br>\n",
    "\n",
    "You may use OpenCV in your function. I'm having you write it for your own convenience, so you don't have to write all the required OpenCV commands every time you want to show an image.\n",
    "\n",
    "Load <tt>donut.jpg</tt> (in color) into a variable <tt>img</tt> and <tt>show</tt> it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2a) Using OpenCV, convert the image to grayscale and <tt>show</tt> it. Do not reload the image. (i.e. convert the image you already loaded to grayscale, save the grayscale version to a separate variable <tt>gray</tt>, and show <tt>gray</tt>.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show(gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2b) <i>Without using OpenCV</i>, write a function <tt>bgr2gray(img)</tt> that converts an M x N x 3 Numpy array representing a BGR image to an M x N array representing a black and white image. According to <a href = \"https://en.wikipedia.org/wiki/Grayscale#Luma_coding_in_video_systems\">Wikipedia</a>, one way to convert the red, green, and blue components of an individual pixel to a single grayscale value is using a weighted sum of the component values: <tt>0.299*r + 0.587*g + 0.114*b</tt>. Your function should not have any loops. Ensure that the data type of the resulting array is the same as the original array, <i>rounding values to the nearest integer as necessary</i>. \n",
    "<br>\n",
    "Use it to convert the image you already loaded to grayscale, save the grayscale version to a separate variable <tt>gray2</tt>, then show <tt>gray2</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show(gray2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2c) What is the maximum (absolute) difference between the grayscale values in the two grayscale arrays? Write an expression that calculates this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2d) If you've rounded correctly, the number of pixels that differ between the two arrays should be 27. Write an expression that calculates this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2e) What is the sum of the (absolute) difference between the two grayscale arrays? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2f) How does this compare to the difference between a pure white array and a pure black array of the same size? In other words, how different are the two compared to the maximum possible difference? Calculate this as a percentage or equivalent decimal, e.g. I get a difference of about .00005%. I'm just trying to show you that this must be how OpenCV is converting to grayscale. Perhaps it uses slightly different weights or the same weights with greater precision, but it must be doing something similar under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0062578222778468e-07"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3a) Use OpenCV to threshold the image and  <tt>show</tt> the result, <tt>thresh</tt>. Find a threshold value that results in a pure white donut over a black background. It's OK if there a few speckles of white from the \"shutterstock\" watermark <i>inside</i> the donut hole, but there should be none outside. A few black speckles inside the donut is OK, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show(thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3b) <i>Without using OpenCV</i>, write a function <tt>threshold(gray,tval,high)</tt> that can perform the same operation, provided the grayscale image <tt>gray</tt>, the threshold value <tt>tval</tt>, and the value to which pixels above the threshold value should be set <tt>high</tt>. Use it to threshold <tt>gray</tt>, save the result to a separate variable <tt>thresh2</tt>, then show <tt>thresh2</tt>. Of course, it should be visiually indistinguishable from <tt>thresh1</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show(thresh2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3c) Write a simple expression that returns <tt>True</tt> if <tt>thresh</tt> and <tt>thresh2</tt> are identical. It should return <tt>True</tt>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "4a) Without modifying <tt>img</tt>, use OpenCV to show the donut (in color) with an outline around the <i>outside</i> of the donut only. If you end up with a green rectangle around the box at the bottom, it's OK, but crop it out of the image before showing the result. \n",
    "\n",
    "<i>The outline should be green and 5 pixels wide.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4b) Show <tt>img</tt> again so that I can see it is unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5a) Load <tt>bunny.jpg</tt> into a variable <tt>img2</tt> and show it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show(img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5b) Using OpenCV, replace the background of the image with blue and show it. Do not modify <tt>img2</tt>.  It's OK if some of the bunny's fur is a bit greenish, as it seems that green light from the backdrop reflected onto the bunny's fur when the photo was taken. However, the green floor under the bunny should not be visible. (Ask me if you think you have it; I'll let you know. This is not intended to be an exercise in precisely identifying appropriate ends of the green color range. If you're having serious trouble identifying the right color values, it's probably because you're missing a step that makes the job of identifying the green hue much easier...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5c) Without using OpenCV, do the same job and show the result. This time, a bit of a halo is acceptable, and it's OK if the green floor immediately under the bunny is visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
